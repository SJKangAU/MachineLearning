{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this homework, you'll be applying the K-nearest neighbor (KNN) classification algorithm to a real-world machine learning data set. In particular, we will predict the affordability of a car given a diverse set of features, including the make, engine type, style,  and horsepower and other descriptive properties of the car.\n",
    "\n",
    "Firstly, you will read in the dataset into a train and a test set, and you will create two feature sets (Q1). Secondly, you will implement different distance functions (Q2). Thirdly, you will implement one KNN classifier (Q3, Q4) and apply it to the data set using different distance functions and parameter K (Q5). Finally, you will assess the quality of your classifier by comparing its class predictions to the gold standard labels (Q6).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Loading the data\n",
    "\n",
    "**Instructions:** For this assignment we will develop a K-Nearest Neighbors (KNN) classifier to predict the \n",
    "affordability of cars. The list of classes is:\n",
    "\n",
    "```\n",
    "cheap\n",
    "affordable\n",
    "expensive\n",
    "very expensive\n",
    "```\n",
    "\n",
    "We use a modified version of the Car data set from the UCI Machine learning repository.\n",
    "\n",
    "The original data can be found here: https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "\n",
    "The dataset consists of 204 instances. Each instance corresponds to a car which has a unique identifier (X; first field) and is characterized with 24 features as described in the file *car.names* which is provided as part of this assignment.\n",
    "\n",
    "You need to first obtain this dataset, which is on Canvas (assignment 1). The files *car.features* and *car.labels* contain the data we will use in this notebook. Make sure the files are saved in the same folder as this notebook. \n",
    "\n",
    "Both files are in comma-separated value format. The first line in each file is a header, naming each feature (or label).\n",
    "\n",
    "*car.features* contains 204 instances, one line per instance. The first field is the unique instance identifier. The following fields contain the 24 features, as described in the file *car.names*.\n",
    "\n",
    "*car.labels* contains the gold labels (i.e., one of the four classes above), one instance per line. Again, the first field is the instance identifier, and the second field the instance label.\n",
    "\n",
    "*car.names* contains additional explanations about the data set and the features.\n",
    "\n",
    "All feature values are floats, and for Questions 1 through 5, we make the simplifying assumption that all values are indeed real-valued. You may want to revisit this assumption in Question 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Task**: Read the two files  \n",
    "1. create a **training_feature** set (list of features for the first 163 instances in the car.* files) and a **training_label** set (list of labels for the corresponding). \n",
    "2. create a **test_feature** set (list of features of the remaining instances in the car.* files) and a **test_label** set (list of labels for the corresponding). \n",
    "---------\n",
    "- Do **not** shuffle the data.\n",
    "- Do **not** modify feature or label representations. \n",
    "- Features must be represented as floats.\n",
    "--------\n",
    "You may use any Python packages you want, but not change the specified data types (i.e., they should be of type List, and *not* dataframe, dictionary etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train/test instances: 163 40\n",
      "number of train/test features: 25 25\n"
     ]
    }
   ],
   "source": [
    "data = open(\"car.features\", 'r').readlines()\n",
    "labels = open(\"car.labels\", 'r').readlines()\n",
    "\n",
    "#To get the first 163 as training then remaining as test\n",
    "train_features = []\n",
    "train_labels   = []\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "\n",
    "\n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "data = [row.strip().split(',') for row in data[1:]]\n",
    "data = [[float(val) for val in row] for row in data]\n",
    "\n",
    "labels = labels[1:]\n",
    "labels = [row.strip().split(',')[1] for row in labels]\n",
    "\n",
    "train_features = data[:163]\n",
    "train_labels = labels[:163]\n",
    "test_features = data[164:]\n",
    "test_labels = labels[164:]\n",
    "## YOUR CODE ENDS HERE\n",
    "###########################\n",
    "\n",
    "print(\"number of train/test instances:\",len(train_features), len(test_features))\n",
    "print(\"number of train/test features:\",len(train_features[40]), len(test_features[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Distance Functions\n",
    "\n",
    "<b>Instructions</b>: Implement the three distance functions specified below. \n",
    "\n",
    "1. Euclidean distance\n",
    "2. Cosine distance\n",
    "3. Chebyshev distance, defined as:\n",
    "    \n",
    "    $d(x,y)=\\max_{i}|x_i-y_i|$\n",
    "    \n",
    "\n",
    "Each distance function takes as input\n",
    "- Two feature vectors (each of type List)\n",
    "\n",
    "and returns as output\n",
    "- The distance between the two feature vectors (float)\n",
    "\n",
    "------------\n",
    "\n",
    "Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409.15785\n",
      "400.0\n",
      "0.99981\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def euclidean_distance(fw1, fw2):\n",
    "    \n",
    "    distance = 0\n",
    "    for x1,x2 in zip(fw1,fw2):\n",
    "        distance = distance + (x1-x2)**2\n",
    "    \n",
    "    distance = math.sqrt(distance)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "def cosine_distance(fw1, fw2):\n",
    "    \"cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for x,y in zip(fw1,fw2):\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    distance = sumxy/math.sqrt(sumxx*sumyy)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "def chebyshev_distance(fw1, fw2):\n",
    "    # insert code here\n",
    "    distance = 0\n",
    "    dist = []\n",
    "    for x,y in zip(fw1,fw2):\n",
    "        dist.append(abs(x-y))\n",
    "        \n",
    "    distance = max(dist)\n",
    "    return distance\n",
    "\n",
    "###########################\n",
    "## YOUR CODE ENDS HERE\n",
    "###########################\n",
    "\n",
    "print(round(euclidean_distance(train_features[100],test_features[2]), 5))\n",
    "print(round(chebyshev_distance(train_features[100],test_features[2]), 5))\n",
    "print(round(cosine_distance(train_features[100],test_features[2]), 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: KNN Classifier\n",
    "\n",
    "<b>Instructions</b>: Here, you implement your KNN classifier. It takes as input \n",
    "- training data features\n",
    "- training data labels\n",
    "- test data features\n",
    "- parameter K\n",
    "- distance function(s) based on which nearest neighbors will be identified\n",
    "\n",
    "It returns as output \n",
    "- the predicted labels for the test data\n",
    "\n",
    "**Ties among distances**. If there are more than K instances with the same (smallest) distance value, consider the first K. For example, for K=1 if you have 3 instances (with identifiers i = 3, 12, 54) that all have the same distance to your test instance (e.g., 0.641), the instance with the smallest identifier should be selected as the nearest neighbor (in this case i = 3).\n",
    "\n",
    "**Ties at prediction time.** Ties can also occur at class prediction time when two (or more) classes are supported by the same number of neighbors. In that case choose the class of the 1 nearest neighbor. The \"1 nearest neighbor\" refers only to those classes represented with the maximum support in the neighborhood. E.g., for K = 5, with a neighborhood ordered by distance: {'cheap', 'expensive', 'affordable', expensive', 'affordable'} you would choose the 1 nearest neighbor among {'expensive','affordable'}.\n",
    "\n",
    "-----------\n",
    "\n",
    "**You should implement the classifier from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library. You may use Python packages (e.g., math, numpy, collections, ...) to help with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances=[np.apply_along_axis(lambda x:euclidean_distance(x,test_case), 1, train_features_array) for test_case in test_features] # apply dist_fun to each test_case for every training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_distances_with_labels = [zip(*sorted(zip(distance,train_labels))) for distance in distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b = list(sorted_distances_with_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = 1/(np.array(a[:5])+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'weights':weights,'labels':b[:5]}).groupby('labels').sum().idxmax().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'weights':weights,'labels':b[:5]}).groupby('labels').sum().idxmax().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheap'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3\n",
    "# max(b[:k],key=b[:k].count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = Counter(b[:1])\n",
    "# sorted(d.items(),key=lambda x: x[1],reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def KNN(train_features, train_labels, test_features, k, dist_fun, weighted=False):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    ###########################\n",
    "    ## Your answer BEGINS HERE\n",
    "    ###########################\n",
    "\n",
    "\n",
    "    \n",
    "    epsilon = 0.000001\n",
    "    train_features_array = np.array(train_features)   #convert to numpy array to use numpy functions\n",
    "    distances=[np.apply_along_axis(lambda x:dist_fun(x,test_case), 1, train_features_array) for test_case in test_features] # apply dist_fun to each test_case for every training instance\n",
    "    sorted_distances_with_labels = [zip(*sorted(zip(distance,train_labels))) for distance in distances] # Sort the distances with labels. Ties among distances is handled with this automatically by sorted(no need to do it manually)\n",
    "    if weighted:\n",
    "        for sdl in sorted_distances_with_labels: # for each sorted list of distances with labels (for each test instance)\n",
    "            d,l=sdl #d is the distance, l is the label\n",
    "            weights = 1/(np.array(d[:k])+epsilon) # weights are 1/(distance + epsilon)\n",
    "            answer = pd.DataFrame({'weights':weights,'labels':l[:k]}).groupby('labels').sum().idxmax().values[0] # get the label with the highest weight\n",
    "            predictions.append(answer) # append the answer to the predictions list\n",
    "    else:\n",
    "        for sdl in sorted_distances_with_labels:\n",
    "            d,l=sdl #d is the distance, l is the label\n",
    "            predictions.append(max(l[:k],key=l[:k].count)) # get the label with the highest count. Ties at prediction time are handled with this automatically by max(no need to do it manually)\n",
    "    \n",
    "            \n",
    "            \n",
    "    ###########################\n",
    "    ## Your answer ENDS HERE\n",
    "    ###########################\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Weighted KNN Classifier \n",
    "\n",
    "<b>Instructions</b>: Extend your implementation of the KNN classifier in Question 3 to a Weighted KNN classifier. You should change the code in the cell above. Use Inverse Distance as weights:\n",
    "\n",
    "$w_j=\\frac{1}{d_j+\\epsilon}$\n",
    "\n",
    "where\n",
    "\n",
    "- $d_j$ is the distance of of the jth nearest neighbor to the test instance\n",
    "- $\\epsilon=0.000001$\n",
    "\n",
    "Use the Boolean parameter `weighted` to specify the KNN version when calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Applying your KNN classifiers to the Car Dataset \n",
    "\n",
    "**Using the functions you have implemented above, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "For each of the distance functions you implemented in Question 2, construct (a) Nine majority voting KNN classifiers and (b) Nine weighted KNN classifiers, respectively, with \n",
    "\n",
    "- K=1\n",
    "- K=5\n",
    "- k=20\n",
    "\n",
    "You will obtain a total of 18 (3 distance functions x 3 K values x 2 KNN versions) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model, where the accuracy is the fraction of correctly predicted labels over all predictions. Use the `accuracy_score` function from the `sklearn.metrics` package to obtain your accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the *full* feature set\n",
      "\n",
      "euclidean (majority vote)\n",
      "K=1 0.375\n",
      "K=5 0.5\n",
      "K=20 0.525\n",
      "-----------\n",
      "euclidean (weighted)\n",
      "K=1 0.375\n",
      "K=5 0.475\n",
      "K=20 0.575\n",
      "\n",
      "cosine (majority vote)\n",
      "K=1 0.25\n",
      "K=5 0.275\n",
      "K=20 0.2\n",
      "-----------\n",
      "cosine (weighted)\n",
      "K=1 0.25\n",
      "K=5 0.275\n",
      "K=20 0.2\n",
      "\n",
      "chebyshev (majority vote)\n",
      "K=1 0.35\n",
      "K=5 0.375\n",
      "K=20 0.5\n",
      "-----------\n",
      "chebyshev (weighted)\n",
      "K=1 0.35\n",
      "K=5 0.425\n",
      "K=20 0.525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "########################\n",
    "# Your code STARTS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy_knn_euc_1 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, euclidean_distance))\n",
    "accuracy_knn_euc_5 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, euclidean_distance))\n",
    "accuracy_knn_euc_20 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, euclidean_distance))\n",
    " \n",
    "accuracy_knn_euc_1_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, euclidean_distance, True))\n",
    "accuracy_knn_euc_5_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, euclidean_distance, True))\n",
    "accuracy_knn_euc_20_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, euclidean_distance, True))\n",
    "\n",
    "accuracy_knn_cos_1 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, cosine_distance))\n",
    "accuracy_knn_cos_5 =  accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, cosine_distance))\n",
    "accuracy_knn_cos_20 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, cosine_distance))\n",
    "\n",
    "accuracy_knn_cos_1_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, cosine_distance, True))\n",
    "accuracy_knn_cos_5_w =  accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, cosine_distance, True))\n",
    "accuracy_knn_cos_20_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, cosine_distance, True))\n",
    "\n",
    "accuracy_knn_che_1 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, chebyshev_distance))\n",
    "accuracy_knn_che_5 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, chebyshev_distance))\n",
    "accuracy_knn_che_20 = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, chebyshev_distance))\n",
    " \n",
    "accuracy_knn_che_1_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 1, chebyshev_distance, True))\n",
    "accuracy_knn_che_5_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 5, chebyshev_distance, True))\n",
    "accuracy_knn_che_20_w = accuracy_score(test_labels, KNN(train_features, train_labels, test_features, 20, chebyshev_distance, True))\n",
    "\n",
    "########################\n",
    "# Your code ENDS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "print(\"Results on the *full* feature set\")\n",
    "\n",
    "print(\"\\neuclidean (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_euc_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_euc_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_euc_20, 3))\n",
    "\n",
    "print(\"-----------\\neuclidean (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_euc_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_euc_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_euc_20_w, 3))\n",
    "\n",
    "print(\"\\ncosine (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_cos_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_cos_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_cos_20, 3))\n",
    "\n",
    "print(\"-----------\\ncosine (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_cos_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_cos_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_cos_20_w, 3))\n",
    "\n",
    "print(\"\\nchebyshev (majority vote)\")\n",
    "print(\"K=1\", round(accuracy_knn_che_1, 3))\n",
    "print(\"K=5\", round(accuracy_knn_che_5, 3))\n",
    "print(\"K=20\", round(accuracy_knn_che_20, 3))\n",
    "\n",
    "print(\"-----------\\nchebyshev (weighted)\")\n",
    "print(\"K=1\", round(accuracy_knn_che_1_w, 3))\n",
    "print(\"K=5\", round(accuracy_knn_che_5_w, 3))\n",
    "print(\"K=20\", round(accuracy_knn_che_20_w, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Analysis\n",
    "\n",
    "1. Consider the following features: make, fuel-type, body-style, and num-of-doors. Assume we intend to use KNN with euclidean distance, for each of the above features, would you change the approach we chose to convert nominal to numeric features? If yes, explain what approach you would select and discuss one benefit and one drawback of your proposed approach.\n",
    "\n",
    "    \n",
    "2. Consider these two sets of attributes: (curb-weight,engine-size) and (compression-ratio, peak-rpm)\n",
    "\n",
    "    (a) For each set of features, create a scatter plot of data points coloring instances from each class differently. You should produce **two plots** which show the scattered data points colored by class label. Label the x-axis and y-axis. [*N.B. you may use libraries like <a href=\"https://matplotlib.org/stable/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py\">matplotlib</a> or <a href=\"https://seaborn.pydata.org/introduction.html\">seaborne</a>*] \n",
    "    \n",
    "    (b) Which feature set is more informative in the context of this classification task and why?\n",
    "    \n",
    "    (c) What do you observe about the relationship between features in each feature set and how did you come to that conclusion?\n",
    "    \n",
    "    \n",
    "3. Discuss the appropriateness of each of the distance functions for our *car* data set. Where appropriate, explain why you expect them to perform poorly referring to both their mathematical properties and the given feature set. \n",
    "\n",
    "    \n",
    "\n",
    "4. Does the Weighted KNN outperform the Majority voting version, or vice versa? Hypothesize why (not). \n",
    "\n",
    "\n",
    "\n",
    "5. Do you think the accuracy is an appropriate evaluation metric for the *car* data set? Why (not)? \n",
    "\n",
    " \n",
    "\n",
    "<b>Each question should be answered in no more than 3-4 sentences.</b>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1\n",
    "\n",
    "2\n",
    "\n",
    "*Type code for 2.(a) in the cell below, and answer 2.(b) and 2.(c) below*\n",
    "\n",
    "2b)\n",
    "\n",
    "2c)\n",
    "\n",
    "3\n",
    "\n",
    "4\n",
    "\n",
    "5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################\n",
    "# Your answer to Question 6 (2) STARTS HERE\n",
    "################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Your answer to Question 6 (2) ENDS HERE\n",
    "################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
